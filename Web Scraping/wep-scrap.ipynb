{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from getNewsSoup import get_news\n",
    "from getNewsSoup import get_content\n",
    "from getNewsSoup import get_news_from_finans\n",
    "from getNewsSoup import get_news_from_roza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total news :  180462\n",
      "total days : 2670\n"
     ]
    }
   ],
   "source": [
    "path = '../Data/news-data.csv'\n",
    "\n",
    "past_dates = [\n",
    "    '/20' + date.split('-')[0].split('.')[::-1][0] + \n",
    "        '/' +date.split('-')[0].split('.')[::-1][1] + \n",
    "            '/' + date.split('-')[0].split('.')[::-1][2]\n",
    "                for date in pd.read_csv(path)['Day_month_year_hour']\n",
    "        ]\n",
    "\n",
    "print(\"total news : \", len(past_dates))\n",
    "past_dates = list(set(past_dates))\n",
    "print(\"total days :\", len(past_dates))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_day = 3000\n",
    "start_day = 0\n",
    "end_day = start_day + max_day"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len Dates list 552\n"
     ]
    }
   ],
   "source": [
    "# Hesaplanan tarihlerin listesi\n",
    "dates = []\n",
    "\n",
    "def main(start_day, end_day, getToday):\n",
    "    # Şu anki tarih ve saat bilgisini al\n",
    "    current_date = datetime.now()\n",
    "    \n",
    "    if(getToday):\n",
    "        # Şu anki yıl, ay ve gün bilgilerini al\n",
    "        year = str(current_date.year)\n",
    "        month = str(current_date.month)\n",
    "        day = str(current_date.day)\n",
    "\n",
    "        # Ay ve gün bilgilerini iki haneli yapma (01, 02, ..., 09)\n",
    "        if len(month) == 1:\n",
    "            month = \"0\" + month\n",
    "        if len(day) == 1:\n",
    "            day = \"0\" + day\n",
    "\n",
    "        # Bugünün tarihini \"/YYYY/MM/DD\" formatında listeye ekleme\n",
    "        dates.append(\"/\" + year + \"/\" + month + \"/\" + day)\n",
    "    \n",
    "    # Belirtilen aralıkta tarihleri oluşturma\n",
    "    for i in range(start_day, end_day):\n",
    "        # Güncel tarihten önceki günleri hesapla\n",
    "        previous_date = current_date - timedelta(days= i)\n",
    "\n",
    "        # Önceki tarihin yıl, ay ve gün bilgilerini al\n",
    "        year = str(previous_date.year)\n",
    "        month = str(previous_date.month)\n",
    "        day = str(previous_date.day)\n",
    "\n",
    "        # Ay ve gün bilgilerini iki haneli yapma (01, 02, ..., 09)\n",
    "        if len(month) == 1:\n",
    "            month = \"0\" + month\n",
    "        if len(day) == 1:\n",
    "            day = \"0\" + day\n",
    "\n",
    "        # Oluşturulan tarihi \"/YYYY/MM/DD\" formatında listeye ekleme\n",
    "        date = \"/\" + year + \"/\" + month + \"/\" + day\n",
    "\n",
    "        if date not in past_dates:\n",
    "            dates.append(date)\n",
    "\n",
    "    # Oluşturulan tarih listesini geri döndürme\n",
    "    return dates\n",
    "\n",
    "# Fonksiyonu çağırarak belirli bir gün aralığındaki tarihleri hesapla\n",
    "dates = list(set(main(start_day=start_day, end_day=end_day, getToday=False)))\n",
    "print(f\"len Dates list {len(dates)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_urls = []  \n",
    "# Haber türlerini (örneğin, yaşam, ekonomi, spor) tutacak liste\n",
    "news_types = []  \n",
    "# Haber başlıklarını tutacak liste\n",
    "titles = []  \n",
    "# Haber tarih ve saat bilgilerini tutacak liste\n",
    "date_time_list = []  \n",
    "# Haber görsel URL'lerini tutacak liste\n",
    "image_urls = []  \n",
    "# Haber içeriklerini tutacak liste\n",
    "contents = []  \n",
    "\n",
    "df = pd.DataFrame(columns=['Title', 'Content', 'Content_url', 'News_type', 'Day_month_year_hour', 'Img_url'])\n",
    "\n",
    "def append_data(title=\"\", content='', content_url='', news_type='', date_time='', img_url=''):\n",
    "    df.loc[len(df)] = [title, content, content_url, news_type, date_time, img_url]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "340 days left\n",
      "330 days left\n",
      "320 days left\n",
      "310 days left\n",
      "300 days left\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 41\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[38;5;66;03m# Eğer class sadece tek bir değerden oluşuyorsa ('box') o zaman bu haberi alıyoruz\u001b[39;00m\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;66;03m# Haber içeriğinin URL'sini al\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     content_url \u001b[38;5;241m=\u001b[39m box\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhref\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 41\u001b[0m     head_url \u001b[38;5;241m=\u001b[39m \u001b[43mcontent_url\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msplit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m        \n\u001b[0;32m     43\u001b[0m     \u001b[38;5;66;03m# Haberin türünü al\u001b[39;00m\n\u001b[0;32m     44\u001b[0m     news_type \u001b[38;5;241m=\u001b[39m box\u001b[38;5;241m.\u001b[39mfind_all(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdiv\u001b[39m\u001b[38;5;124m\"\u001b[39m, attrs\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minfo\u001b[39m\u001b[38;5;124m\"\u001b[39m})[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mfind(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mtext\u001b[38;5;241m.\u001b[39mstrip()\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Geçerli URL'nin indeksi\n",
    "current_url_index = 0  \n",
    "\n",
    "# Yasaklı URL'ler listesi, farklı HTML yapılarına sahip olanlar\n",
    "banned_urls = []\n",
    "# Yasaklı haberlerin listesi\n",
    "banned_news = []\n",
    "# Haber içeriklerinin URL'lerini tutacak liste\n",
    "\n",
    "# Yasaklı bağlantıların listesi\n",
    "banned_hrefs = []\n",
    "\n",
    "# Açilmayan sayfa sayısı\n",
    "counter = 0\n",
    "\n",
    "# Ana döngü, belirli bir tarih aralığındaki haberleri almak için kullanılır\n",
    "while True:\n",
    "    # Veriyi almak için URL'yi fonksiyona veriyoruz.\n",
    "    soup = get_news(url=\"/timeline\" + dates[current_url_index], day_news=True)\n",
    "    \n",
    "    # Sayfa açılmadıysa bu if çalışmaz ve current_url_index değişmez, böylece sayfa değişmez\n",
    "    if soup is not None and len(soup.find_all('div', attrs={'class': 'box'})) != 0:\n",
    "        \n",
    "        # İlerlemeyi adım adım takip etmek için\n",
    "        remaining_days = len(dates) - (current_url_index )\n",
    "        if remaining_days % 10 == 0:\n",
    "            print(f\"{remaining_days} days left\")\n",
    "        \n",
    "        if remaining_days % 5:\n",
    "            df.to_csv(\"../Data/data_39.csv\", encoding='utf-8', index=False)\n",
    "            \n",
    "        # news_boxes, o günün bütün haberlerini içeriyor\n",
    "        for box in soup.find_all('div', attrs={'class': 'box'}):\n",
    "            box_classes = box.get(\"class\")\n",
    "\n",
    "            # Her bir haberin class'i 'box['box'], reklam olanların class'i 'box advert'['box', 'advert'], uzunluğu 2 olduğu için reklamları almıyoruz\n",
    "            if len(box_classes) == 2:\n",
    "                pass\n",
    "\n",
    "            # Eğer class sadece tek bir değerden oluşuyorsa ('box') o zaman bu haberi alıyoruz\n",
    "            else:\n",
    "                # Haber içeriğinin URL'sini al\n",
    "                content_url = box.find('a').get(\"href\")\n",
    "                \n",
    "                try:\n",
    "                    head_url = content_url.split(\"/\")[1]        \n",
    "\n",
    "                    # Haberin türünü al\n",
    "                    news_type = box.find_all(\"div\", attrs={\"class\": \"info\"})[0].find(\"a\").text.strip()\n",
    "                    \n",
    "                    # Haber başlığını al\n",
    "                    title = box.find('strong').text.strip() \n",
    "                    \n",
    "                    # Haber tarih ve saat bilgisini al\n",
    "                    current_date = box.find('div', {'class': \"info\"}).find(\"label\").text.strip()\n",
    "                    date_time = current_date.split(\" \")[0].split(\",\")[0] + '-' + current_date.split(\" \")[-1]\n",
    "                    \n",
    "                    # Haber görsel URL'sini al\n",
    "                    image_url = box.find(\"img\").get('src')\n",
    "\n",
    "                    # URL 'roza' ile başlıyorsa, özel bir fonksiyon kullanarak haber içeriğini al\n",
    "                    if head_url == \"roza\":\n",
    "                        roza_news = get_news_from_roza(content_url)\n",
    "                        append_data(title=title, content=roza_news, content_url=content_url, news_type=news_type, date_time=date_time, img_url=image_url)\n",
    "\n",
    "                    # 'roza' ile başlamayan ve yasaklı URL'ler içinde olmayan haber başlıklarını al\n",
    "                    elif head_url not in banned_urls:\n",
    "                        content_soup = get_news(url=content_url)\n",
    "                        if content_soup is not None:\n",
    "                            \n",
    "                            content_check = content_soup.find_all(\"div\", attrs={\"class\": \"col-sm-12 view20 pagedItems\"})\n",
    "\n",
    "                            # Eğer haber içeriğinde birden fazla fotoğraf varsa class yapısı değişiyor ve burada o haberin bu sayfa yapısına sahip olup \n",
    "                            # olmadığını kontrol ediyoruz \n",
    "                            if len(content_check) == 0:\n",
    "                                news_content = get_content(content_soup=content_soup)\n",
    "                                append_data(title=title, content=news_content, content_url=content_url, news_type=news_type, date_time=date_time, img_url=image_url)\n",
    "                            # Eğer haber birden fazla fotoğraf ve içerikten oluşuyorsa bu şart sağlanır\n",
    "                            else:    \n",
    "                                news_content = get_content(content_soup=content_soup, url=\" pagedItems\")\n",
    "                                append_data(title=title, content=news_content, content_url=content_url, news_type=news_type, date_time=date_time, img_url=image_url)\n",
    "                    \n",
    "                    elif head_url == \"finans\":\n",
    "                        \n",
    "                        finans_news = get_news_from_finans(content_url)\n",
    "                        append_data(title=title, content=finans_news, content_url=content_url, news_type=news_type, date_time=date_time, img_url=image_url)\n",
    "                        \n",
    "                    else:\n",
    "                        # Eğer URL 'roza', 'finans' ve 'spor' sayfalarına giriyorsa geç\n",
    "                        banned_hrefs.append(content_url)\n",
    "                except:\n",
    "                    pass\n",
    "        current_url_index += 1        \n",
    "\n",
    "    # Eğer sayfa açılmazsa current_url_index değişmez ve döngü tekrar aynı sayfayı deneyecektir\n",
    "    else:\n",
    "        counter += 1\n",
    "\n",
    "    # İstenen gün sayısına ulaşıldığında döngüyü sonlandır\n",
    "    if current_url_index == len(dates):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 17771 entries, 0 to 17770\n",
      "Data columns (total 6 columns):\n",
      " #   Column               Non-Null Count  Dtype \n",
      "---  ------               --------------  ----- \n",
      " 0   Title                17771 non-null  object\n",
      " 1   Content              17771 non-null  object\n",
      " 2   Content_url          17771 non-null  object\n",
      " 3   News_type            17771 non-null  object\n",
      " 4   Day_month_year_hour  17771 non-null  object\n",
      " 5   Img_url              17771 non-null  object\n",
      "dtypes: object(6)\n",
      "memory usage: 971.9+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/data_39.csv\", encoding='utf-8', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
